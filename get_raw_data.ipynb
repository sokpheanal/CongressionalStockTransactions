{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproducible steps to create a corpus from [FinnHub](https://finnhub.io/).\n",
    "\n",
    "# Pseudocode\n",
    "\n",
    "Below is a list of the steps we take.\n",
    "Keep in mind that these steps are a 10 thousand foot view.\n",
    "The implementation will be commented to a more detailed level.\n",
    "\n",
    "1. Get the tickers from the [SEC](https://www.sec.gov/file/company-tickers)\n",
    "2. Using the retrieved data, get the tickers for every publicly traded stock in the U.S. market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from dotenv import load_dotenv, dotenv_values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_url = 'https://www.sec.gov/files/company_tickers.json'\n",
    "user_agent = 'FinnHub-Data-Ingestion'\n",
    "limit = 20\n",
    "\n",
    "data_folder = Path('./data/')\n",
    "tickers_file = data_folder.joinpath('./tickers.csv')\n",
    "raw_folder = data_folder.joinpath('./raw')\n",
    "corpus_folder = data_folder.joinpath('./corpus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "\n",
    "1. Get the list of tickers from the SEC\n",
    "2. Convert the tickers into an array, then sort it.\n",
    "3. Save the tickers to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tickers(tickers_file: Path, tickers_url: str, user_agent: str, ) -> pd.DataFrame:\n",
    "    if not tickers_file.exists():\n",
    "        tickers = None\n",
    "        with requests.Session() as session:\n",
    "            session.headers['User-Agent'] = user_agent\n",
    "            with session.get(tickers_url) as result:\n",
    "                if result.status_code == 200:\n",
    "                    t1 = json.loads(result.text)\n",
    "                    t2 = [x for x in t1.values()]\n",
    "                    t3 = sorted(t2, key = lambda tup: tup['ticker'])\n",
    "                    tickers = [(x['cik_str'], x['ticker'], x['title']) for x in t3]\n",
    "        if tickers is not None:\n",
    "            df = pd.DataFrame(tickers, columns = ['CIK', 'Ticker', 'Name'])\n",
    "            if not tickers_file.parent.exists():\n",
    "                tickers_file.parent.mkdir(parents = True)\n",
    "            df.to_csv(tickers_file, index = False)\n",
    "        else:\n",
    "            raise RuntimeError('Error retrieving tickers')          \n",
    "    return pd.read_csv(tickers_file) #type: ignore\n",
    "\n",
    "tickers_df = get_tickers(tickers_file, tickers_url, user_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "\n",
    "1. Iterate through each ticker in the `tickers.csv` file and download all available trading data.\n",
    "2. Save data of each ticker to JSON files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "base_url = f'https://finnhub.io/api/v1/stock/congressional-trading?symbol='\n",
    "\n",
    "headers = {\n",
    "        'Accept': '/',\n",
    "        'User-Agent': 'Thunder Client (https://www.thunderclient.com)',\n",
    "        'X-FinnHub-Token': os.getenv(\"API_KEY\"), # Replace with your actual API key\n",
    "                }\n",
    "\n",
    "tickers = tickers_df['Ticker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in tqdm(tickers):\n",
    "    url = base_url + str(ticker)\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if 'transactionDate' in data:\n",
    "            filename = f'data/raw/{ticker}.json'\n",
    "            with open(filename, 'w') as jsonfile:\n",
    "                jsonfile.write(response.text)\n",
    "            print(f'Response for {ticker} saved to {filename}')\n",
    "        else:\n",
    "            print(f'No trade data available for {ticker}. Skipping.')\n",
    "    else:\n",
    "        print(f'Failed to retrieve data for {ticker}. Status code: {response.status_code}')\n",
    "\n",
    "print(\"Data download completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
